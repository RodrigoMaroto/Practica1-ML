{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80be4647-ebbc-474f-a886-b0799cb7b764",
   "metadata": {},
   "source": [
    "# Practica 1: Predicción de la producción de energía eólica con SCIKIT-LEARN\n",
    "## Parte 2: Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fb6d5b-305b-4b0d-82a7-52434c9ca720",
   "metadata": {},
   "source": [
    "### Procesamiento de datos\n",
    "En primer lugar cargamos los datos y aplicamos el mismo tratamiento que en la primera parte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a5c242-8789-4129-832f-92de86b60bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e1b61a-1273-4d24-a8e8-b985deec6b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_ava = pd.read_csv('dataset/wind_ava.csv.gz', compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a1e37ef-7197-4a3c-94c8-98214d17b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_ava[\"datetime\"] = pd.to_datetime(wind_ava[\"datetime\"])\n",
    "wind_ava.set_index(\"datetime\", inplace=True)\n",
    "for c in wind_ava.columns:\n",
    "  if not c.endswith(\".13\") and c != \"energy\":\n",
    "    wind_ava.drop(c, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d07ea1e-0e62-4130-bfb8-cb7744c7f8be",
   "metadata": {},
   "source": [
    "A continuación, añadimos una columna de \"class\" que tendrá valor 1 si el valor de la energía se encuentra por encima del tercer cuartil, y 0 si es inferior. Consideraremos 1 como clase \"alta\" y 0 como clase \"baja\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28c6195-121c-4101-bf98-866c12243806",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = wind_ava[\"energy\"].quantile(q=0.75)\n",
    "wind_ava[\"class\"] = wind_ava.apply(lambda row: 1 if row[\"energy\"]>=limit else 0,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b891f-d075-4279-9474-6eee24ffeb35",
   "metadata": {},
   "source": [
    "### Evaluación modelo de regresión para valores altos y bajos\n",
    "A continuación, vamos a entrenar el modelo escogido en la Parte 1, con los datos del conjunto de train. Para los subconjuntos de train y test usaremos los mismos que en la anterior sección. Tras entrenar el modelo, haremos una predicción para los valores de test. Estas predicciones las dividimos en altas y bajas y comparamos su RMSE por separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35458502-889d-40bc-b450-e0b5fb46298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efc45a76-c4f8-4487-90b5-262fd8f718cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = len([0 for x in wind_ava.index if x.year >=2009])\n",
    "train, test = train_test_split(wind_ava, test_size=test_size, shuffle=False)\n",
    "X_train = train.drop(['energy', 'class'], axis='columns')\n",
    "y_train = train[['energy']]\n",
    "X_test = test.drop(['energy', 'class'], axis='columns')\n",
    "y_test = test[['energy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d5aa57f-a906-4247-af69-85a9a8973c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('svm', SVR(kernel=\"rbf\", C=900, epsilon=2.25))]\n",
    ")\n",
    "pipe.fit(X_train, np.ravel(y_train))\n",
    "predictions =  pipe.predict(X_test)\n",
    "y_test.insert(0,\"predictions\", predictions)\n",
    "y_high = y_test[y_test[\"energy\"]>=limit]\n",
    "y_low = y_test[y_test[\"energy\"]<limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdea7a3f-d256-47c9-9226-0113097a8547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE global: 386.7961147673092 \n",
      "RMSE para valores altos: 597.7465977875753 \n",
      "RMSE para valores bajos: 289.89758524036023\n"
     ]
    }
   ],
   "source": [
    "rmse = root_mean_squared_error(y_test[\"energy\"], y_test[\"predictions\"])\n",
    "rmse_high = root_mean_squared_error(y_high[\"energy\"], y_high[\"predictions\"])\n",
    "rmse_low = root_mean_squared_error(y_low[\"energy\"], y_low[\"predictions\"])\n",
    "print(\"RMSE global:\", rmse,\"\\nRMSE para valores altos:\",rmse_high, \"\\nRMSE para valores bajos:\", rmse_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91966e4c-b659-4f66-83d9-cb20dfb8beb5",
   "metadata": {},
   "source": [
    "Podemos observar como las predicciones para valores altos tienen un mayor error frente a los valores bajos que se encuentran por debajo de la media, que coincide con el rendimiento esperado en la Parte 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978b0b99-5c39-4af8-95fb-e102ad7887f8",
   "metadata": {},
   "source": [
    "### Problema de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7cca24-f848-4650-86d8-2e98af64ee90",
   "metadata": {},
   "source": [
    "A continuación vamos a evaluar el rendimiento de diferentes clasificadores en este nuevo problema de regresión. Usaremos los conjuntos de train y test definidos anteriormente y con las clases generadas en la primera sección de este programa. Los clasificadores a comparar son los siguientes:   \n",
    "* Clasificador Dummy: Este clasificador unicamente devuelve la clase mayoritaria. Como tenemos dos clases bastante desbalanceadas, la precisión es probable que se situe en torno al 0.75 pero la precision balanceada por clase será siempre 0.5.\n",
    "* Árbol de decision: Para este clasificador usaremos dos versiones, para comparar los resultados usando diferentes pesos de clases para balancear nuestros datos. Es de esperar que las clases balanceadas den un mejor rendimiento.\n",
    "* Vecinos más cercanos: Los datos usados en estos en este clasificador serán escalados previamente con StandardScaler(), elegido en la parte 1, ya que es muy sensible a las unidades.\n",
    "* Naive Bayes: Este clasificador probabilistico basado en el Teorema de Bayes tiene la ventaja de ser muy rapido haciendo predicciones frente a KNN que tiene que calcular un gran número de distancias.\n",
    "   \n",
    "Las métricas de evaluación que usaremos son:\n",
    "* Accuracy: La métrica más comun y simple, aunque la información que aporta es insuficiente en casos con clases desbalanceadas, ya que incluso los clasificadores Dummy obtienen buenos resultados pero no evalua el rendimiento en las clases minoritarias.\n",
    "* Recall/TPR: Accuracy para una de las clases, en el caso de este modelo, mide la de la clase mayoritaria \"baja\".\n",
    "* TNR: Accuracy para la otra clase, \"alta\".\n",
    "* Accuracy balanceada (BAC): Esta métrica es la media del TPR y el TNR, y devuelve un valor más representativo que obliga a clasificar de manera correcta ambas clases para obtener un mejor resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92b066e6-0131-426c-8d46-4f1ca35eb5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier:\n",
      "Accuracy: 0.7600\n",
      "Recall/TPR: 1.0000\n",
      "TNR: 0.0000\n",
      "Balanced Accuracy: 0.5000\n",
      "\n",
      "Decision Tree (unbalanced) Classifier:\n",
      "Accuracy: 0.7970\n",
      "Recall/TPR: 0.8600\n",
      "TNR: 0.5973\n",
      "Balanced Accuracy: 0.7286\n",
      "\n",
      "Decision Tree (balanced) Classifier:\n",
      "Accuracy: 0.8143\n",
      "Recall/TPR: 0.8843\n",
      "TNR: 0.5928\n",
      "Balanced Accuracy: 0.7385\n",
      "\n",
      "Nearest Neighbors Classifier:\n",
      "Accuracy: 0.8350\n",
      "Recall/TPR: 0.9286\n",
      "TNR: 0.5385\n",
      "Balanced Accuracy: 0.7335\n",
      "\n",
      "Naive Bayes Classifier:\n",
      "Accuracy: 0.7362\n",
      "Recall/TPR: 0.7557\n",
      "TNR: 0.6742\n",
      "Balanced Accuracy: 0.7150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, balanced_accuracy_score\n",
    "\n",
    "classifiers = {\n",
    "    \"Dummy\": DummyClassifier(strategy=\"most_frequent\", random_state=454455),\n",
    "    \"Decision Tree (unbalanced)\": DecisionTreeClassifier(random_state=454455),\n",
    "    \"Decision Tree (balanced)\": DecisionTreeClassifier(class_weight=\"balanced\", random_state=454455),\n",
    "    \"Nearest Neighbors\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"knn\", KNeighborsClassifier())\n",
    "    ]),\n",
    "    \"Naive Bayes\":Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"nb\", GaussianNB())\n",
    "    ])\n",
    "}\n",
    "\n",
    "X_train = train.drop(['energy', 'class'], axis='columns')\n",
    "y_train = train[['class']]\n",
    "X_test = test.drop(['energy', 'class'], axis='columns')\n",
    "y_test = test[['class']]\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, np.ravel(y_train))\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=0)\n",
    "    tnr = recall_score(y_test, y_pred)\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{name} Classifier:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Recall/TPR: {recall:.4f}\")\n",
    "    print(f\"TNR: {tnr:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1276f3f6-fac3-41a1-b18a-1759b4c5e97b",
   "metadata": {},
   "source": [
    "Para obtener conclusiones sobre este nuevo problema, vamos a fijarnos en la balanced accuracy, que tiene en cuenta el desbalanceo de las clases. Además, deberemos comparar los resultados de los modelos con el modelo dummy para asegurarnos de que el modelo es positivo.\n",
    "El modelo que presenta mayor balanced accuracy es de nuevo KNN, que además es el que tiene una tasa de recall más alta. Esta medida nos indica cuantos valores positivos son correctamente clasificados. \n",
    "También nos gustaría señalar la diferencia entre el método de árboles de decisión balanceados y no balanceados, habiendo arrojado el primero mejores resultados. \n",
    "Por útlimo, nos gustaría mencionar la importancia de utilizar la balanced accuracy en lugar de la accuracy normal. Por ejemplo, si no tenemos en cuenta este desbalanceo, el clasificador basado en naive Bayes podría parecer peor que el modelo dummy si nos fijamos en la accuracy normal. Sin embargo, si tenemos en cuenta el desbalanceo de las clases, vemos que en realidad presenta mejores resultados el primero. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
